receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  prometheus/collector:
    config:
      scrape_configs:
        - job_name: 'opentelemetry-collector'
          static_configs:
            - targets: ['localhost:8888']

  docker_stats:
    collection_interval: 10s
    timeout: 20s
    excluded_images:
      - telemetry
    metrics:
      container.cpu.usage.percpu:
        enabled: true
      container.cpu.utilization:
        enabled: true


  kafkametrics:
    brokers: kafka:9092
    protocol_version: 2.0.0
    scrapers:
      - brokers
      - topics
      - consumers
    collection_interval: 10s

  postgresql:
    endpoint: db:5432
    tls:
      insecure: true
    username: postgres
    password: password
    collection_interval: 10s
    connection_pool:
      max_idle_time: 10m
      max_lifetime: 0
      max_idle: 2
      max_open: 2

  sqlquery/metrics:
    collection_interval: 10s
    datasource: "postgresql://postgres:password@db/bookapp?sslmode=disable"
    driver: postgres
    initial_delay: 5s
    queries:
      - sql: |-
          select count(*) as count from books
        metrics:
          - metric_name: bt.sql_books_count
            value_column: "count"

processors:
  resourcedetection:
    detectors: [ env, system ]

  memory_limiter:
    check_interval: 1s
    limit_percentage: 10
    spike_limit_percentage: 5

  #filter:

  deltatocumulative:

  resource/logs:
    attributes:
      - key: "injected_resource_attribute"
        action: "insert"
        value: "otel-collector"

  attributes/logs:
    # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/attributesprocessor/README.md
    actions:
      - key: "name"
        pattern: ^(?:event\s+)?(?P<file_path>[^\s:]+):(?P<line_number>\d+)
        action: extract
      - key: line_number
        action: convert
        converted_type: int
      - key: "name-copied"
        action: "upsert"
        from_attribute: name
      - key: "name"
        action: "delete"


  transform/logs:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          - set(resource.attributes["container_id"], resource.attributes["host.name"])
          - delete_key(resource.attributes, "host.name")
          - set(attributes["level"], severity_text)

  # To play nicer with prometheus we will add some extra labels to the metrics from the resource
  # attributes
  # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/dockerstatsreceiver/documentation.md#resource-attributes
  transform/metrics/docker_stats:
    error_mode: ignore
    metric_statements:
      - context: datapoint
        statements:
          - set(attributes["hostname"], resource.attributes["container.hostname"])
          - set(attributes["container_name"], resource.attributes["container.name"])
          - set(attributes["image_name"], resource.attributes["container.image.name"])

  transform/metrics/kafka:
    error_mode: ignore
    metric_statements:
      - context: datapoint
        statements:
          - set(attributes["cluster_alias"], resource.attributes["kafka.cluster.alias"])

  batch:
    timeout: 10s

exporters:
  otlphttp/metrics:
    endpoint: http://localhost:9090/api/v1/otlp
    tls:
      insecure: true
  otlphttp/traces:
    endpoint: http://localhost:4418
    tls:
      insecure: true
  otlphttp/logs:
    endpoint: http://localhost:3100/otlp
    tls:
      insecure: true
  debug/metrics:
    verbosity: detailed
  debug/traces:
    verbosity: detailed
  debug/logs:
    verbosity: detailed

#  otlphttp/axiom:
#    compression: gzip
#    endpoint: https://api.axiom.co
#    headers:
#      authorization: Bearer ${env:AXIOM_API_KEY}
#      x-axiom-dataset: rust-telemetry-example-bookapp

connectors:
  # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/connector/exceptionsconnector
  exceptions:


  # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/connector/countconnector/README.md
  count:
    logs:
      bt_service_log_count:
        description: The number of logs from each file.
        attributes:
          - key: file_path
            default_value: unspecified_file_path

    spanevents:
      bt.span.event.count:
        description: The number of span events originating from the bookapp/db module.
        conditions:
          - 'attributes["code.namespace"] == "bookapp::db"'


service:

  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, batch]
      exporters: [exceptions, otlphttp/traces]
      #exporters: [otlphttp/traces, otlphttp/axiom]

    traces/count:
      receivers: [otlp]
      processors: [batch]
      exporters: [count]

    metrics:
      receivers:
        - otlp
        - prometheus/collector
        - postgresql
        - sqlquery/metrics
#        - count
        - exceptions
      processors: [memory_limiter, batch]
      exporters: [otlphttp/metrics]

    metrics/counts:
      receivers: [count]
      processors: [deltatocumulative, batch]
      exporters: [otlphttp/metrics]

    metrics/kafka:
      receivers: [kafkametrics]
      processors: [memory_limiter,transform/metrics/kafka,batch]
      exporters: [otlphttp/metrics]
      # Enable debugging
      #exporters: [otlphttp/metrics, debug/metrics]

    metrics/docker:
      receivers: [docker_stats]
      processors: [memory_limiter,transform/metrics/docker_stats,batch]
      exporters: [otlphttp/metrics]

    logs:
      receivers: [otlp]
      processors: [memory_limiter,resourcedetection,resource/logs,transform/logs,attributes/logs,batch]
      exporters: [otlphttp/logs, count]
